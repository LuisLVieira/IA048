{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf1e2f6",
   "metadata": {},
   "source": [
    "# IA048A - EFC 02: Classificação\n",
    "\n",
    "### Luís Antônio Almeida Lima Vieira (221045)  &  Nathan Shen Baldon (242448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38dc2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# É necessário antes de tudo instalar a biblioteca medmnist\n",
    "\n",
    "# Importações necessárias\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os \n",
    "from tqdm import tqdm\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42) # indica onde escolha aleatória começa\n",
    "\n",
    "# to make pretty figures\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "EFC = \"efc2\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", EFC)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"svg\"):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e35a347",
   "metadata": {},
   "source": [
    "## Importação da base de dados Breastmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bca6c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedMNIST v2.1.0 @ https://github.com/MedMNIST/MedMNIST/\n"
     ]
    }
   ],
   "source": [
    "print(f\"MedMNIST v{medmnist.__version__} @ {medmnist.HOMEPAGE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8355ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o dataset breastmnist\n",
    "data_flag = 'breastmnist'\n",
    "download = True\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b40acd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\nsbal\\.medmnist\\breastmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\nsbal\\.medmnist\\breastmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\nsbal\\.medmnist\\breastmnist.npz\n"
     ]
    }
   ],
   "source": [
    "# carregando os dados\n",
    "train_dataset = DataClass(split='train', download=download)\n",
    "val_dataset = DataClass(split='val', download=download)\n",
    "test_dataset = DataClass(split='test', download=download)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ee665a",
   "metadata": {},
   "source": [
    "- Informações sobre a base de dados _BreastMNIST_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e192220",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python_class': 'BreastMNIST',\n",
       " 'description': 'The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.',\n",
       " 'url': 'https://zenodo.org/record/6496656/files/breastmnist.npz?download=1',\n",
       " 'MD5': '750601b1f35ba3300ea97c75c52ff8f6',\n",
       " 'task': 'binary-class',\n",
       " 'label': {'0': 'malignant', '1': 'normal, benign'},\n",
       " 'n_channels': 1,\n",
       " 'n_samples': {'train': 546, 'val': 78, 'test': 156},\n",
       " 'license': 'CC BY 4.0'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e033bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os labels por conjunto:\n",
    "train_labels = train_dataset.labels\n",
    "val_labels = val_dataset.labels\n",
    "test_labels = test_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21244387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando as imagens por conjunto:\n",
    "train_img = train_dataset.imgs\n",
    "val_img = val_dataset.imgs\n",
    "test_img = test_dataset.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2a20970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rótulo: [1]\n",
      "Saving figure imagem_um\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAYAAACHjumMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOoklEQVR4nO3dX0/UZxrG8RuBAWEGkBGkgq1NYxubnjSxBz3sO+m76wvo2+hRTWNSrIktWuSPgFig8m+PttlsnN/zTZwrm2y+n0P32XvGmfHaX7JX7mfi+vq6JCnhxv/6DUj6/2XASIoxYCTFGDCSYgwYSTFTXf/hDz/8MLb/i4n+v1UTExPNM9PT02jW3Nxc88zNmzfRLPKaMzMzaNbUVOfHXlXsc6iq+vvvv5tn6OdF3hd5vaqqyclJdO7du3djOVPFvsu3b9+iWcRgMEDnzs/Pm2dOTk7QrBs32s8E9H1dXFw0z5DfRFXVo0eP3vuD9QlGUowBIynGgJEUY8BIijFgJMUYMJJiDBhJMQaMpBgDRlJMZ03vxx9/REPm5+ebZ2iz882bN+gcQVqP/X4fzVpZWWme2djYQLNI45S2V0lDenZ2Fs06Ojpqntnb20OzyG+iqury8rJ5ptfroVkLCwvNM/T9k++b/L4o+h2R13z8+DGa9ddffzXP0N/ho0eP3vvnPsFIijFgJMUYMJJiDBhJMQaMpBgDRlKMASMpxoCRFMP24TWQchxdJ7m2tvahb+cfZ2dnYzlTxQpaZAVhVdXx8XHzzOHhIZq1tLTUPLO+vo5mkfe1s7ODZtHPlaywvH37Npo1quz1n27duoVmke+SFu1IiY7+dkg5jlpcXGyeubq6+qDX8AlGUowBIynGgJEUY8BIijFgJMUYMJJiDBhJMQaMpBgDRlJMZ5OXtvjIhejLy8toFmmd7u/vo1lPnz5tnqHNYXoZPUFek7ZXycrJFy9eoFmkrUzWalbx3w5p/NK1jU+ePGmeIe3VKtb4JS3qqqrffvuteYZ+XuR90bbyYDBoniHrXbv4BCMpxoCRFGPASIoxYCTFGDCSYgwYSTEGjKQYA0ZSTGfR7uTkBA0h6/7oCsXNzc3mGVLsq6qammpvBN3a2kKzCHI3clXVgwcPmmdosY+8Jp1F70cmxrnakd5NTdaMkmJiVdXc3NxYXq+KFdrGWbSjf8eDg4Pmmd3dXTRrFJ9gJMUYMJJiDBhJMQaMpBgDRlKMASMpxoCRFGPASIoxYCTFdFZdaYOSXAJOWoNVVa9evWqeoa1g0nqcnp5Gs0h7mDZhyd+RtoLJ5fGk0VzF1knSvyNda0pWcJ6fn6NZw+GweYa+f9JEJm3fqqo7d+40z9C1oOT7pv/WVldXm2f6/T6aNYpPMJJiDBhJMQaMpBgDRlKMASMpxoCRFGPASIoxYCTFdDawaNmLFO3o+k1yFy5dVXh8fNw8Q9ZXVrGyGv28yJ3GX375JZpFClp0hSIp2tFiIi1pknubSTGxit1/Tstx19fXzTPPnj1Ds3Z2dppnaBlynHdTE/Tf2ig+wUiKMWAkxRgwkmIMGEkxBoykGANGUowBIynGgJEUY8BIiumsD5KGblXV/Px888znn3+OZpHWI2l/VrHVmvfu3UOzHj582DxDW6Lb29vNM7T5TF6TXmD+yy+/NM/QdaW08UtWU9KVmaTVPDMzg2aR3yFZX1lV9fHHHzfP0BY4aSuTFZ1V7LczOTmJZo3iE4ykGANGUowBIynGgJEUY8BIijFgJMUYMJJiDBhJMZ1Fu7W1NTSEFO2++uorNIvcVUxWO1ax+5FpOe7Nmzdjeb2qqtPT0+YZchd2FSvkXV1doVmk7EXvUKb3I5N5tIRGVoPSu5bJb4x+rmSFJV1r+vz58+YZWqwkJTr67+Pbb79975/7BCMpxoCRFGPASIoxYCTFGDCSYgwYSTEGjKQYA0ZSjAEjKaazyUubihMTE80zm5ubaNbe3l7zDGnCVrEmMm12DofD5hnaeiTnaIuatEQvLi7QLNK+ffz4MZpF26SkwUo/V/JdDgYDNIs0jGlzu9frNc+Qf0NVVRsbG80zdNUt+eynpjojov1ePui/LUkdDBhJMQaMpBgDRlKMASMpxoCRFGPASIoxYCTFdLZovvvuOzSErHekxavV1dXmGXpXMSkc0RLX9fV18wy9t5kU2o6Pj9Gsu3fvNs/QvyO5J5reOU2+xypWMCP3MVdVraysNM/Q9ZukaLe1tYVmjbPQRla30nvNSemQFDm7+AQjKcaAkRRjwEiKMWAkxRgwkmIMGEkxBoykGANGUowBIymmsz74008/oSEPHz5snqErIEnL9dmzZ2ObRVcozs7OonPE0tJS8wxde0hWkZIWchVbV0ravlWsCVvFPgv6mqTxSy61r2IXw9P2LVmZefPmTTSLtHRpC3x+fr55hrbAR/EJRlKMASMpxoCRFGPASIoxYCTFGDCSYgwYSTEGjKSYzqYQLTiRdZi0qEZmzczMoFnjvMeXvCZ5vaqq9fX15hm6JnJnZ6d55unTp2gWKR3evn0bzaLFSoKW9sjqVvpZkHvZyfrKKlbaI6W3KnbPOPkcqliJ7kPvzPYJRlKMASMpxoCRFGPASIoxYCTFGDCSYgwYSTEGjKQYA0ZSTGeTl64EfPXqVfMMbWOSBujXX3+NZpH28J9//olm/fHHH80zdMUoaVrSFYofffRR88wXX3yBZpEVo+RMFbvwvYqtgJyenkazSPv25cuXaBY5R1dTkiZvv99Hs8j6U/pvjVxsT5vbo/gEIynGgJEUY8BIijFgJMUYMJJiDBhJMQaMpBgDRlJMZ5OOFHGq2H2/dM0lKZjRshdZj7i9vY1mkfWICwsLaBYphNFyHCmhPX/+HM0iK1JJaayKr5Mkr0mLY6T49vbtWzSLnPv999/RLFKOo/8+yJpLum51ZWWleWY4HKJZo/gEIynGgJEUY8BIijFgJMUYMJJiDBhJMQaMpBgDRlKMASMpprPJS9uYpClKL5knTV7aJiWXud+7dw/NIpfM0zZmr9drnjk8PESzdnd3m2foakcyi16sTlvgZFUk/R2en583z5D1rlVVW1tbzTO0FXznzp3mGXrJ/Pz8fPPMJ598gmaRRjn9HY7iE4ykGANGUowBIynGgJEUY8BIijFgJMUYMJJiDBhJMQaMpJjOJu/PP/+MhpALsukl2lNTnW+pqvjF8J999lnzDG1QktYmvVidtGFpe3V2drZ55uzsDM0i74u2lcke2qqqo6Oj5hn6uZKWLt2je3Fx0TxD9uPSWRsbG2jW/fv3m2doO311dbV5hraVR/EJRlKMASMpxoCRFGPASIoxYCTFGDCSYgwYSTEGjKSYzlbbkydP0BBS2CGFqqqqtbW15hlyYXoVuzSdFsdI4YisWayq2tzcbJ6hqx1J0W5xcRHNmp6ebp4haymrqk5PT9G5k5OTsb3m/v5+8wwpvVWxz5UW7cj6ULIKs4q9f/rb+fXXX5tnyG+iquqbb75575/7BCMpxoCRFGPASIoxYCTFGDCSYgwYSTEGjKQYA0ZSjAEjKaazyfvpp5+iIaTRSJuKZL0jaVlWsZboixcv0KyDg4PmGdIcrmJtzL29vbHNokir+fLyEs2i7Vsyb2FhAc2anJwcy5mqqn6/3zyzvLyMZpHP9cYN9r/1ZBUp/Y7I35GsUe3iE4ykGANGUowBIynGgJEUY8BIijFgJMUYMJJiDBhJMZ1FO3pvMyna0dWUpDi2vb2NZpFCXq/XQ7NIeYmu8iTn6H3SZKUhWdlYVTUYDJpnaGGS3h9OCnl0bSNBC4zkbnBSvqxi75/e5U2Kb0tLS2gWcXV1hc59//337/1zn2AkxRgwkmIMGEkxBoykGANGUowBIynGgJEUY8BIijFgJMV0Nnl3dnbQEHIx/HA4RLNIs5O0LKvGe4E5Wb9JkfWIU1OdX80/yFrT+/fvo1mk1Xx4eIhm0VWL5Bz9vklDml4MT1q6dF0paemOc2UmXQtKvm/a3B7FJxhJMQaMpBgDRlKMASMpxoCRFGPASIoxYCTFGDCSYjrbXLQsRcpx9D5pUhKis0hZand3F80i74uuGCV3AlNkBST9HslaU7pykq78JAUzuoqUFD7p+yKfGb1/m3zftGhHyn10PS15X/TzGsUnGEkxBoykGANGUowBIynGgJEUY8BIijFgJMUYMJJiDBhJMWwvY8Pi4mLzDG0E7u/vN8/QZipZO0kvaSct3Xfv3qFZ5By9dJx8FvSzJ5e001l0xShdO0mQ9zbOJu840c/h8vKyeYZ+9uQ39qHfj08wkmIMGEkxBoykGANGUowBIynGgJEUY8BIijFgJMV0NtG2t7fREFLGoWsiSfmHlI2qWIluMBigWbT4RpDPixYA19bWmmeWl5fRLIJ+DmR9ZRW7/5wWx8i92fT9k7WT9HdI3j+5c7pqvIVPcuc3fV+j+AQjKcaAkRRjwEiKMWAkxRgwkmIMGEkxBoykGANGUowBIymms8lLL5kn7UjaxiSveffuXTSLtFzprMnJyeaZo6MjNItc5v769Ws0izQ7aauWrBjt9XpoFr3MnXzfZJVnVdXp6WnzzO7u7thmkd9EFWtl078jec3j42M0izSRz8/P0axRfIKRFGPASIoxYCTFGDCSYgwYSTEGjKQYA0ZSjAEjKaazWbW+vo6GzM3NNc/QtY0rKyvNM7SUREpCZM1iFburmJa4Dg4OmmdIGa+Kr0ckSDnuQ1co/jdSHKPlPnJuOByiWaScSFdmkrWs9A5osuaSluPId0mKnF18gpEUY8BIijFgJMUYMJJiDBhJMQaMpBgDRlKMASMpxoCRFNPZ5CXt1SrW5CUNRIquYySrA8e5XpA0dKuqzs7OmmfoZ0/WldL27ThbwbTlSt4//b7H2QomDVb6uZL1p2StZlXVrVu3mmfoZ0/+TZLfahefYCTFGDCSYgwYSTEGjKQYA0ZSjAEjKcaAkRRjwEiK6SzakbuKq1gpjBbaSFmNvi+y9pDe20xKVXTNJSkv0RWKpFxGi1fkNeksirzmONd00tJev99vnqFrYEm5j/4OyedPiq9V7LdD76cfxScYSTEGjKQYA0ZSjAEjKcaAkRRjwEiKMWAkxRgwkmIMGEkxE+O+zFyS/s0nGEkxBoykGANGUowBIynGgJEUY8BIivkXc9evrWAHxWEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vizualização da primeira imagem do conjunto de treinamento\n",
    "print(f\"Rótulo: {train_labels[0]}\")\n",
    "plt.imshow(train_img[0],cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "save_fig('imagem_um')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fc8f325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rótulo: [0]\n",
      "Saving figure imagem_quatro\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vizualização da quarta imagem do conjunto de treinamento\n",
    "print(f\"Rótulo: {train_labels[4]}\")\n",
    "plt.imshow(train_img[4],cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "save_fig('imagem_quatro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd02ab",
   "metadata": {},
   "source": [
    "## Análise do balanceamento das classes nos conjuntos disponíveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa91475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No conjunto de treinamento há 147 classes negativas\n",
      "Porcentagem de classes negativas: 26.923076923076923 %\n",
      "No conjunto de treinamento há 399 classes positivas\n",
      "Porcentagem de classes positivas: 73.07692307692308 %\n"
     ]
    }
   ],
   "source": [
    "# Conjunto de treinamento\n",
    "num_negativas_t = (train_labels==0).sum()\n",
    "num_positivas_t = (train_labels==1).sum()\n",
    "p_negativas_t = num_negativas_t*100/len(train_labels)\n",
    "p_positivas_t = num_positivas_t*100/len(train_labels)\n",
    "print(\"No conjunto de treinamento há\",num_negativas_t, \"classes negativas\")\n",
    "print(\"Porcentagem de classes negativas:\",p_negativas_t,\"%\")\n",
    "print(\"No conjunto de treinamento há\",num_positivas_t, \"classes positivas\")\n",
    "print(\"Porcentagem de classes positivas:\",p_positivas_t,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db81c768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No conjunto de validação há 21 classes negativas\n",
      "Porcentagem de classes negativas: 26.923076923076923 %\n",
      "No conjunto de validação há 57 classes positivas\n",
      "Porcentagem de classes positivas: 73.07692307692308 %\n"
     ]
    }
   ],
   "source": [
    "# Conjunto de validação\n",
    "num_negativas_v = (val_labels==0).sum()\n",
    "num_positivas_v = (val_labels==1).sum()\n",
    "p_negativas_v = num_negativas_v*100/len(val_labels)\n",
    "p_positivas_v = num_positivas_v*100/len(val_labels)\n",
    "print(\"No conjunto de validação há\",num_negativas_v, \"classes negativas\")\n",
    "print(\"Porcentagem de classes negativas:\",p_negativas_v,\"%\")\n",
    "print(\"No conjunto de validação há\",num_positivas_v, \"classes positivas\")\n",
    "print(\"Porcentagem de classes positivas:\",p_positivas_v,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63367e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No conjunto de teste há 42 classes negativas\n",
      "Porcentagem de classes negativas: 26.923076923076923 %\n",
      "No conjunto de teste há 114 classes positivas\n",
      "Porcentagem de classes positivas: 73.07692307692308 %\n"
     ]
    }
   ],
   "source": [
    "# Conjunto de teste\n",
    "num_negativas_tt = (test_labels==0).sum()\n",
    "num_positivas_tt = (test_labels==1).sum()\n",
    "p_negativas_tt = num_negativas_tt*100/len(test_labels)\n",
    "p_positivas_tt = num_positivas_tt*100/len(test_labels)\n",
    "print(\"No conjunto de teste há\",num_negativas_tt, \"classes negativas\")\n",
    "print(\"Porcentagem de classes negativas:\",p_negativas_tt,\"%\")\n",
    "print(\"No conjunto de teste há\",num_positivas_tt, \"classes positivas\")\n",
    "print(\"Porcentagem de classes positivas:\",p_positivas_tt,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9f9b4c",
   "metadata": {},
   "source": [
    "## Preparando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b56854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando os dados para a regressão logística\n",
    "# Foi transformando o array de matrizes em um único array de dimensão compatível com as labels\n",
    "# Após essas transformações, cada linha dos conjuntos se refere a uma label\n",
    "x_train = np.reshape(train_img,(len(train_labels),28*28))/255 # a divisão por 255 é para normalização dos dados das imagens (maior valor é 255)\n",
    "x_val = np.reshape(val_img,(len(val_labels),28*28))/255\n",
    "x_test = np.reshape(test_img,(len(test_labels),28*28))/255\n",
    "y_train = np.ravel(train_labels)\n",
    "y_val = np.ravel(val_labels)\n",
    "y_test = np.ravel(test_labels)\n",
    "# Criando o conjunto validação+treino para uso posterior\n",
    "x_tv=np.concatenate((x_train,x_val))\n",
    "y_tv=np.concatenate((y_train,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b8aece",
   "metadata": {},
   "source": [
    "## Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88437630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05834877 0.94165123]\n",
      " [0.42038302 0.57961698]\n",
      " [0.32524308 0.67475692]\n",
      " [0.86714305 0.13285695]\n",
      " [0.46531423 0.53468577]\n",
      " [0.08908264 0.91091736]\n",
      " [0.07292875 0.92707125]\n",
      " [0.62444985 0.37555015]\n",
      " [0.08057469 0.91942531]\n",
      " [0.39020684 0.60979316]\n",
      " [0.28897761 0.71102239]\n",
      " [0.52006946 0.47993054]\n",
      " [0.33419816 0.66580184]\n",
      " [0.1799791  0.8200209 ]\n",
      " [0.59009357 0.40990643]\n",
      " [0.07877741 0.92122259]\n",
      " [0.3452313  0.6547687 ]\n",
      " [0.04077405 0.95922595]\n",
      " [0.39277573 0.60722427]\n",
      " [0.05610198 0.94389802]\n",
      " [0.9287656  0.0712344 ]\n",
      " [0.30365474 0.69634526]\n",
      " [0.32681269 0.67318731]\n",
      " [0.15225562 0.84774438]\n",
      " [0.09881963 0.90118037]\n",
      " [0.04982111 0.95017889]\n",
      " [0.32653058 0.67346942]\n",
      " [0.542571   0.457429  ]\n",
      " [0.97462005 0.02537995]\n",
      " [0.11660725 0.88339275]\n",
      " [0.46559366 0.53440634]\n",
      " [0.38329092 0.61670908]\n",
      " [0.02075876 0.97924124]\n",
      " [0.96764782 0.03235218]\n",
      " [0.06409811 0.93590189]\n",
      " [0.45777245 0.54222755]\n",
      " [0.02415065 0.97584935]\n",
      " [0.28463228 0.71536772]\n",
      " [0.3782557  0.6217443 ]\n",
      " [0.3017823  0.6982177 ]\n",
      " [0.13244525 0.86755475]\n",
      " [0.69222098 0.30777902]\n",
      " [0.13975249 0.86024751]\n",
      " [0.0719462  0.9280538 ]\n",
      " [0.67057104 0.32942896]\n",
      " [0.32443365 0.67556635]\n",
      " [0.0794461  0.9205539 ]\n",
      " [0.91566843 0.08433157]\n",
      " [0.32186362 0.67813638]\n",
      " [0.6840606  0.3159394 ]\n",
      " [0.08705201 0.91294799]\n",
      " [0.08200871 0.91799129]\n",
      " [0.25801936 0.74198064]\n",
      " [0.21863661 0.78136339]\n",
      " [0.23319771 0.76680229]\n",
      " [0.37517818 0.62482182]\n",
      " [0.89039228 0.10960772]\n",
      " [0.02363753 0.97636247]\n",
      " [0.08940891 0.91059109]\n",
      " [0.13956269 0.86043731]\n",
      " [0.02752417 0.97247583]\n",
      " [0.0041792  0.9958208 ]\n",
      " [0.11367111 0.88632889]\n",
      " [0.90136572 0.09863428]\n",
      " [0.37494503 0.62505497]\n",
      " [0.1167947  0.8832053 ]\n",
      " [0.97809556 0.02190444]\n",
      " [0.9142241  0.0857759 ]\n",
      " [0.34359699 0.65640301]\n",
      " [0.27349731 0.72650269]\n",
      " [0.14307395 0.85692605]\n",
      " [0.70159538 0.29840462]\n",
      " [0.0843514  0.9156486 ]\n",
      " [0.64427978 0.35572022]\n",
      " [0.89467422 0.10532578]\n",
      " [0.29346184 0.70653816]\n",
      " [0.6761077  0.3238923 ]\n",
      " [0.14880635 0.85119365]]\n",
      "(78, 2)\n",
      "0.8846153846153846\n",
      "0.8589743589743589\n",
      "0.7948717948717948\n"
     ]
    }
   ],
   "source": [
    "# Testando a Regressão Logística\n",
    "# Como o dataset é pequeno, foi escolhido o solver liblinear (conforme instruído na documentação)\n",
    "# Foi escolhido 3000 como o número máximo de iterações, penalidade do tipo l2 com fator de regularização C de 1\n",
    "lr = LogisticRegression(penalty='l2', C=1, class_weight='balanced', solver='liblinear', max_iter=3000)\n",
    "lr.fit(x_train, y_train)\n",
    "# Probabilidades estimadas\n",
    "y_proba = lr.predict_proba(x_val)\n",
    "# Acurácia média\n",
    "score_train= lr.score(x_train, y_train)\n",
    "score_val= lr.score(x_val, y_val)\n",
    "score_test= lr.score(x_test, y_test)\n",
    "print(y_proba)\n",
    "print(y_proba.shape)\n",
    "print(score_train)\n",
    "print(score_val)\n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6219f19",
   "metadata": {},
   "source": [
    "### Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7a7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "# Validação Cruzada pelo GridSearchCV\n",
    "# Foram fixados, dentre os parâmetros da Regressão Logística, apenas o solver como liblinear e as iterações maximas como 3000\n",
    "# Tipo de regularização variando entre l1 e l2 ('none' não se aplica ao solver liblinear):\n",
    "penalty_vector = [\"l1\", \"l2\"]\n",
    "# Valores inversos da força da regularização (valores menores representam regularizações maiores):\n",
    "C_vector = [1000, 100, 10, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "# Peso das classes variando entre balanceado e não balanceado:\n",
    "c_weight_vector = [\"balanced\", None]\n",
    "# dicionário dos parâmetros da regressão logística para a serem utilizados no GridSearchCV\n",
    "dict_grid={'penalty':penalty_vector,'C':C_vector,'class_weight': c_weight_vector}\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=3000)\n",
    "# Foi escolhida a validação cruzada padrão do GridSearchCV que é kfold para 5 folds, será aplicada no conjunto treino+validação\n",
    "# A escolha dos parâmetros visa a maximização da área sob a curva ROC (\"scoring = 'roc_auc'\")\n",
    "# O parâmetro verbose printa mensagens \n",
    "CV = GridSearchCV(estimator=logreg, param_grid=dict_grid, cv=5, verbose=1, scoring='roc_auc')\n",
    "CV_fit=CV.fit(x_tv,y_tv)\n",
    "# Melhores parâmetros\n",
    "CV_fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando com os parâmetros ótimos 'C': 10, 'class_weight': 'balanced', 'penalty': 'l2', solver liblinear (dataset pequeno)\n",
    "lr_opt = LogisticRegression(penalty='l2', C=10, class_weight='balanced', solver='liblinear', max_iter=3000)\n",
    "lr_opt.fit(x_tv, y_tv)\n",
    "# Probabilidades estimadas\n",
    "y_proba_train = lr_opt.predict_proba(x_tv)\n",
    "y_proba_test = lr_opt.predict_proba(x_test)\n",
    "# Acurácia média\n",
    "score_tv= lr_opt.score(x_tv, y_tv)\n",
    "score_test2= lr_opt.score(x_test, y_test)\n",
    "print(y_proba_train)\n",
    "print(y_proba_train.shape)\n",
    "print(y_proba_test)\n",
    "print(y_proba_test.shape)\n",
    "print(\"Acurácia no conjunto de treinamento + validação:\",score_tv)\n",
    "print(\"Acurácia no conjunto de teste:\",score_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf670b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previsão para o conjunto de teste\n",
    "y_pred_test = lr_opt.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f1edbf",
   "metadata": {},
   "source": [
    "### Métricas de desempenho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823814e",
   "metadata": {},
   "source": [
    "- Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e23d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=metrics.confusion_matrix(y_test, y_pred_test)\n",
    "cm_fig=metrics.ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=lr_opt.classes_)\n",
    "cm_fig.plot()\n",
    "plt.title('Confusion matrix')\n",
    "save_fig('cm_lr')\n",
    "plt.show()\n",
    "print(\"É possível perceber que a quantidade de verdadeiros negativos (câncer) é maior que a quantidade de falsos negativos.\")\n",
    "print(\"É possível perceber também que a quantidade de verdadeiros positivos (não câncer) é maior que a quantidade de falsos negativos.\")\n",
    "print(\"Portanto, há mais acertos do que erros nos dados de teste para o modelo escolhido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62613a",
   "metadata": {},
   "source": [
    "- Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f811ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acurácia = (n°verdadeiros positivos + n°verdadeiros negativos)/total\")\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_test)\n",
    "print(\"O valor da acurácia é\",accuracy)\n",
    "print(\"Portanto, o classificador obteve boa taxa de acerto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345ae7c9",
   "metadata": {},
   "source": [
    "- F1-Medida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"precisao = (n°verdadeiros positivos)/(n°verdadeiros positivos + n°falsos positivos)\")\n",
    "print(\"recall = (n°verdadeiros positivos)/(n°verdadeiros positivos + n°falsos negativos)\")\n",
    "print(\"F1 = 2*(recall*precisao)/(recall + precisao)\")\n",
    "F1 = metrics.f1_score(y_test, y_pred_test)\n",
    "print(\"O valor da F1-Medida é\",F1)\n",
    "print(\"Portanto, o classificador obteve bons resultados tanto na precisão quanto no recall.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da466f5b",
   "metadata": {},
   "source": [
    "- Acurácia Balanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e018446",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"especificidade = (n°verdadeiros negativos/(n°verdadeiros negativos + n°falsos positivos)\")\n",
    "print(\"sensibilidade = (n°verdadeiros positivos)/(n°verdadeiros positivos + n°falsos negativos)\")\n",
    "print(\"acurácia balanceada = (especificidade + sensibilidade)/2\")\n",
    "a_b = metrics.balanced_accuracy_score(y_test, y_pred_test)\n",
    "print(\"O valor da acurácia balanceada é\",a_b)\n",
    "print(\"Portanto, os valores de Especificidade não foram tão bons quanto os valores de Recall, que foram muito bons.\")\n",
    "print(\"Ajustando o peso das classes no modelo, essa foi a acurácia balanceada ótima.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de1b57e",
   "metadata": {},
   "source": [
    "- Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a08032",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.plot_roc_curve(lr_opt, x_test, y_test)\n",
    "plt.title('Receiving Operating Curve (ROC)')\n",
    "save_fig('curva_ROC_lr')\n",
    "plt.show()\n",
    "print(\"A curva ROC mostrou que o comportamento do modelo é bem melhor do que um classificador aleatório.\")\n",
    "print(\"Porém, devido à pequena quantidade de dados, houve uma certa distância da curva obtida para uma curva ideal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5743f",
   "metadata": {},
   "source": [
    "## Classificação por KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c722d0",
   "metadata": {},
   "source": [
    "### Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86a7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validação cruzada variando o número de vizinhos, os tipos de pesos e as métricas de distância\n",
    "# Número de vizinhos a serem testados (de 1 vizinho até 50 vizinhos):\n",
    "n_vector=np.arange(1,51)\n",
    "# tipos de pesos a serem testados\n",
    "weights_vector = [\"uniform\", \"distance\"]\n",
    "# Métricas de distância a serem testadas\n",
    "# p=1 usa a distância de Manhattan e p=2 usa a distância de Euclidiana, com metric=minkowski (padrão)\n",
    "p_vector = [1,2]\n",
    "# dicionário de parâmtros\n",
    "KNN_grid={'n_neighbors':n_vector,'weights':weights_vector,'p': p_vector}\n",
    "KNN= KNeighborsClassifier(metric='minkowski')\n",
    "# Validação cruzada pelo GridSearch com 5 folds\n",
    "# A escolha dos parâmetros visa a maximização da acurácia balanceada\n",
    "CV_KNN = GridSearchCV(estimator=KNN, param_grid=KNN_grid, cv=5, verbose=1, scoring=\"balanced_accuracy\")\n",
    "CV_KNN_fit=CV_KNN.fit(x_tv,y_tv)\n",
    "# Melhores parâmetros\n",
    "CV_KNN_fit.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598bb6e",
   "metadata": {},
   "source": [
    "Agora que os parâmetros ótimos (para maximização da acurácia balanceada) são conhecidos, vamos analisar o efeito da variação de k (número de vizinhos) no valor dessa métrica (acurácia balanceada).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_k = []\n",
    "k_vector = np.arange(1,51)\n",
    "\n",
    "# Treinamento com diferentes valores de K e cálculo da acurácia balanceada para a classificação do conjunto de validação \n",
    "for k in k_vector:\n",
    "    KNN = KNeighborsClassifier(n_neighbors=k, weights = 'uniform', p=2, metric='minkowski') # define o modelo com o novo valor de k\n",
    "    KNN.fit(x_train, y_train) # realiza o treinamento (apenas com conjunto de treinamento)\n",
    "    y_pred_val = KNN.predict(x_val) # realiza classificação do conjunto de validação para o novo k\n",
    "    ba_k = np.append(ba_k, metrics.balanced_accuracy_score(y_val, y_pred_val)) # calcula acurácia balanceada para conjunto de validação com novo k\n",
    "                     \n",
    "plt.plot(k_vector,ba_k)\n",
    "plt.xlabel(\"$k$\", fontsize=18)\n",
    "plt.ylabel(\"Acurácia Balanceada\", rotation=90, fontsize=18)\n",
    "save_fig('k_vs_ba')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b439b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando com os parâmetros ótimos 'n_neighbors': 1, 'p': 2, 'weights': 'uniform', metric=minkowski para os dados de validação e treinamento juntos\n",
    "KNN_opt = KNeighborsClassifier(n_neighbors=1, weights = 'uniform', p=2, metric='minkowski')\n",
    "KNN_opt.fit(x_tv, y_tv)\n",
    "# Acurácia média\n",
    "score_tv_knn= KNN_opt.score(x_tv, y_tv)\n",
    "score_test_knn= KNN_opt.score(x_test, y_test)\n",
    "print(score_tv_knn)\n",
    "print(score_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a500224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previsão para o conjunto de teste\n",
    "y_pred_test_knn = KNN_opt.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c9a4eb",
   "metadata": {},
   "source": [
    "### Métricas de desempenho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bdde6d",
   "metadata": {},
   "source": [
    "- Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f50edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_knn=metrics.confusion_matrix(y_test, y_pred_test_knn)\n",
    "cm_fig_knn=metrics.ConfusionMatrixDisplay(confusion_matrix=cm_knn,display_labels=KNN_opt.classes_)\n",
    "cm_fig_knn.plot()\n",
    "plt.title('Confusion matrix (KNN)')\n",
    "save_fig('cm_knn')\n",
    "plt.show()\n",
    "print(\"É possível perceber que a quantidade de verdadeiros negativos (câncer) é maior que a quantidade de falsos negativos.\")\n",
    "print(\"É possível perceber também que a quantidade de verdadeiros positivos (não câncer) é maior que a quantidade de falsos negativos.\")\n",
    "print(\"Portanto, há mais acertos do que erros nos dados de teste para o modelo escolhido.\")\n",
    "print(\"O KNN apresentou um desempenho ligeiramente inferior à regressão logística.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e8790",
   "metadata": {},
   "source": [
    "- Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acurácia = (n°verdadeiros positivos + n°verdadeiros negativos)/total\")\n",
    "accuracy_knn = metrics.accuracy_score(y_test, y_pred_test_knn)\n",
    "print(\"O valor da acurácia é\",accuracy_knn)\n",
    "print(\"Portanto, o classificador obteve boa taxa de acerto.\")\n",
    "print(\"O KNN apresentou uma Acurácia ligeiramente inferior à regressão logística.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a718f92b",
   "metadata": {},
   "source": [
    "- F1-Medida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"precisao = (n°verdadeiros positivos)/(n°verdadeiros positivos + n°falsos positivos)\")\n",
    "print(\"recall = (n°verdadeiros positivos)/(n°verdadeiros positivos + n°falsos negativos)\")\n",
    "print(\"F1 = 2*(recall*precisao)/(recall + precisao)\")\n",
    "F1_knn = metrics.f1_score(y_test, y_pred_test_knn)\n",
    "print(\"O valor da F1-Medida é\",F1_knn)\n",
    "print(\"Portanto, o classificador obteve bons resultados tanto na precisão quanto no recall.\")\n",
    "print(\"O KNN apresentou uma F1-medida ligeiramente inferior à regressão logística.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054902ca",
   "metadata": {},
   "source": [
    "- Acurácia balanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45cc38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"especificidade = (n°verdadeiros negativos/(n°verdadeiros negativos + n°falsos positivos)\")\n",
    "print(\"sensibilidade = (n°verdadeiros positivos)/(n°verdadeiros positivos + n°falsos negativos)\")\n",
    "print(\"acurácia balanceada = (especificidade + sensibilidade)/2\")\n",
    "a_b_knn = metrics.balanced_accuracy_score(y_test, y_pred_test_knn)\n",
    "print(\"O valor da acurácia balanceada é\",a_b_knn)\n",
    "print(\"Valores de Especificidade não foram tão bons e valores de Recall foram muito bons.\")\n",
    "print(\"O KNN apresentou uma Acurácia Balanceada ligeiramente inferior à regressão logística.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
